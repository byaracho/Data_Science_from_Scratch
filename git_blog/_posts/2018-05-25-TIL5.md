---
layout: post
title: "선형대수 04 - 선형대수와 해석기하 (1)"
tags: [데이터분석, 데이터사이언스, 선형대수]
comments: true
---
### 01 벡터의 기하학적 의미
- - -
N차원 백터 $$a$$는 N차원의 공간상에서 벡터 a의 값으로 표시되는 **점(point)** 또는 원점과 벡터 $$a$$의 값으로 표시되는 점을 연결한 **화살표(arrow)**로 간주할 수 있다. 크기 만으로 나타낼 수 있는 스칼라와는 달리 **방향과 크기**를 사용할 수 있다는 점이 특징이다.<br />
<img width="720" alt="2018-05-25 2 58 39" src="https://user-images.githubusercontent.com/35296703/40528478-279d1334-602c-11e8-9ec0-4bdc97544561.png"><br />
<br />

### 02 벡터의 길이
- - -
**2차원 벡터** $$a$$의 길이는 **피타고라스 정리**를 이용하여 계산할 수 있으며, 그 값은 **벡터의 놈(norm)** $$\| a \|$$이다. N차원 벡터의 길이도 마찬가지로 벡터의 놈으로 정의한다.<br />
<br />
$$ \| a \| = \sqrt{a^T a } = \sqrt{a_1^2 + \cdots + a_N^2} $$<br />[출처](https://datascienceschool.net/view-notebook/dd1680bfbaab414a8d54dc978c6e883a/)
<br />

### 03 스칼라와 벡터의 곱
- - -
양의 실수와 벡터를 곱하면 벡터의 방향은 변하지 않고, 실수의 크기 만큼 벡터의 **길이**가 커진다. 만약 음의 실수를 곱하면 벡터의 방향이 반대가 된다.<br />
<img width="717" alt="2018-05-25 3 15 05" src="https://user-images.githubusercontent.com/35296703/40529119-6d9ac15e-602e-11e8-98fd-a2088db06900.png"><br />
<br />

### 04 단위 벡터(unit vector)
- - -
길이가 1인 벡터(즉, 벡터의 놈이 1인 벡터)를 단위 벡터라고 한다.<br />
<br />
임의의 벡터 $$x$$의 단위 벡터 : $$ \dfrac{x}{\| x \|} $$<br />
<br />

### 05 벡터의 합
- - -
벡터와 벡터의 합도 벡터가 된다. 두 벡터의 합으로 만들어진 벡터는 두 벡터를 이웃한 변으로 가진 **평행사변형의 대각선**이 된다.<br />
<img width="725" alt="2018-05-25 3 20 53" src="https://user-images.githubusercontent.com/35296703/40529327-3e91776c-602f-11e8-91d7-91d6a7d0bd85.png"><br />
<br />

### 06 벡터의 차
- - -
벡터의 차 $$a-b=c$$는 벡터 b(출발점)가 가리키는 점으로부터 벡터 a가 가리키는 점을 연결하는 벡터이다.<br />
<img width="732" alt="2018-05-25 3 23 20" src="https://user-images.githubusercontent.com/35296703/40529417-a2b9bbbe-602f-11e8-9da3-5a70afeaacb8.png"><br />
이러한 개념은 하나의 단어를 공간상의 벡터로 표현하여 단어간의 관계를 나타내는 word2vec 방식에서 사용된다.<br />
<br />

### 07 유클리드 유사도
- - -
두 벡터가 가리키는 점의 거리를 구한 것을 **유클리드 거리(Euclidean distance)**라고 한다. 유클리드 거리가 작아질수록(두 벡터가 가까울수록) 커지는 값을 **유클리드 유사도(Euclidean similarity)**라고 한다<br />
<br />
$$ \begin{eqnarray} 
\| a - b \|^2
&=& \sum_{i=1} (a_i - b_i)^2 \\
&=& \sum_{i=1} a_i^2 + \sum_{i=1} b_i^2 - 2 \sum_{i=1} a_i b_i \\
&=& \| a \|^2 + \| b \|^2  - 2 a^Tb
\end{eqnarray} $$<br />
<br />

### 08 벡터의 내적과 코사인 유사도
- - -
두 벡터의 **내적**은 다음처럼 구할 수도 있다.<br />
<br />
$$ a^Tb = \|a\|\|b\| \cos\theta $$<br />
<br />
$$ \cos\theta $$는 직각삼각형에서 빗변 $$a$$와 아랫변 $$b$$의 길이의 비율을 의미한다.<br />
<br />
$$ \cos\theta = \dfrac{b}{a} $$<br />
<br />
두 벡터 $$a$$와 $$b$$가 이루는 각이 90도이면 서로 직교(orthogonal)라고 하며 $$a \perp b$$로 표시한다. $$\cos 90^{\circ} = 0$$이므로 서로 직교인 두 벡터의 내적은 0이 된다.<br />
<br />
두 벡터의 방향이 비슷할수록 내적이 커지는 성질을 이용하여 **내적의 값**을 두 벡터의 유사도로 간주하는 것이 **코사인 유사도(cosine similarity)**이다. 코사인 유사도는 상품이나 영화에 대한 **만족도, 평점**을 평가할 때 많이 사용한다.<br />
<br />
$$ \text{코사인 유사도} = \dfrac{x^Ty}{\|x\|\|y\|} $$<br />
$$ \text{코사인 거리} = 1 - \text{코사인 유사도} = 1 - \dfrac{x^Ty}{\|x\|\|y\|} $$<br />
<br />

### 09 벡터의 분해와 성분
- - -
어떤 두 벡터 $$a, b$$의 합이 다른 벡터 c가 될 때, c가 두 벡터 **성분(vector component)** $$a, b$$로 **분해(decomposition)**된다고 한다.<br />
##### 투영
벡터 $$a$$를 다른 벡터 $$b$$에 직교하는 성분과 벡터 $$b$$에 평행한 성분으로로 분해할 수 있는데, 벡터 $$b$$에 **수직**인 성분을 벡터  $$b$$에 대한 **리젝션 벡터(rejection vector)**, **평행**한 성분을 벡터 $$b$$에 대한 **프로젝션 벡터(projection vector)**라고 하며 각각 다음과 같이 표기한다.<br />
<br />
$$a^{\perp b}$$와 $$a^{\Vert b}$$
<br />
a^{\Vert b} = \dfrac{a^Tb}{\|b\|} \dfrac{b}{\|b\|}= \dfrac{a^Tb}{\|b\|^2}b<br />
<br />
a^{\perp b} = a - a^{\Vert b}<br />
<img width="737" alt="2018-05-25 3 44 20" src="https://user-images.githubusercontent.com/35296703/40530128-86fbd8aa-6032-11e8-89f9-93c9ef43c716.png"><br />
<br />

### 10 행렬식의 기하학적 의미
- - -
정방 행렬의 **행렬식의 절대값**은 그 행렬의 열 벡터(또는 행벡터)들이 이루는 **평행사변형(2x2행렬의 경우)의 면적 또는 부피**가 된다.

### 11 직선의 방정식
- - -
임의의 벡터 $$w$$에 **수직**이면서, $$w$$가 **가리키는 점**을 지나는 직선의 방정식을 구해보자. 벡터 $$x$$가 해당 직선의 점이라고 할 때, 두 조건을 만족하기 위해서는 벡터 $$x$$가 가리키는 점과 벡터 $$w$$가 가리키는 점을 이은 **벡터 $$x-w$$**가 **벡터 $$w$$**와 **직교**해야 한다.<br />
<br />
$$ w^T(x - w) = w^Tx - w^Tw = w^Tx - \| w \|^2 = 0 $$<br />
<img width="721" alt="2018-05-25 3 57 29" src="https://user-images.githubusercontent.com/35296703/40530605-65f97ce6-6034-11e8-998c-3d0a3133c311.png"><br />
$$w$$에 스칼라 곱을 한 벡터 $$w'=cw$$에 수직인 직선의 방정식은 다음과 같을 것이다.<br />
<br />
$$ w^Tx - c \| w \|^2 = 0 $$<br />
<br />
만일 특정한 점을 지난다는 조건이 없으면, 다음과 같다.<br />
<br />
$$ w^Tx - w_0 = 0 $$<br />
<br />
여기에서 $$w_{0}$$은 원점으로부터 직선에 내린 **수선의 길이의 제곱**이다.<br />
<br />

### 12 직선과 점의 거리
- - -
직선 $$w^Tx - \|w\|^2 = 0$$과 직선 위에 있지 않은 점 $$x'$$의 거리는 **벡터 $$w$$에 대한 $$x'$$의 프로젝션 벡터의 길이**에서 **$$\|w\|$$를 뺀 값**의 **절대값**이다.<br />
<br />
$$ \left|  \|x'^{\Vert w}\| - \|w\| \right| = 
\left| \dfrac{w^Tx'}{\|w\|} - \|w\| \right| =
\dfrac{\left|w^Tx' - \|w\|^2 \right|}{\|w\|} $$<br />
<br />
직선의 방정식이 $$w^Tx - w_0 = 0$$이면 직선과 점의 거리는 다음과 같다.<br />
<br />
$$ \dfrac{\left|w^Tx' - w_0 \right|}{\|w\|} $$<br />
<img width="716" alt="2018-05-25 4 06 09" src="https://user-images.githubusercontent.com/35296703/40530943-939eaa4e-6035-11e8-8900-b979cd83a791.png"><br />
<br />

**참고 자료**<br />
[김도형 박사님의 데이터 사이언스 스쿨](www.datascienceschool.net)<br />
[위키피디아-벡터](https://ko.wikipedia.org/wiki/벡터)<br />
<br />





